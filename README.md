This repository contains a collection of Jupyter notebooks designed for implementing and evaluating a teacher-student distillation framework to annotate RECIST-based clinical outcomes. The notebooks are organized in a sequential manner and cover all major steps, from dataset creation to model training and evaluation. Below is a description of each notebook and its purpose.

1. Data Preparation
##1a_make_recist_teacher_dataset.ipynb
Purpose: Prepares the RECIST-based dataset for training the teacher model. This includes processing raw clinical data, generating labels for longitudinal clinical outcomes (e.g., progression and response), and formatting the dataset for downstream tasks.
Output: A structured dataset with RECIST labels ready for teacher model training.

##1b_make_synthetic_data_gpt4.ipynb
Purpose: Uses GPT-4 to generate synthetic data that mimics the structure and content of clinical datasets. Prompts are carefully designed to emulate RECIST-based text while maintaining variability.
Output: A synthetic dataset generated by GPT-4, which serves as an alternative training dataset for the student model.

2. Teacher Model Training
##2a_train_teacher_HTransformer_pd.ipynb
Purpose: Trains the teacher model using a hierarchical transformer (HTransformer) architecture with longitudinal patient-level dataset containing PHI from primary DFCI cohort.
Output: A trained teacher model capable of predicting progressive disease based on the RECIST dataset.

##2b_train_teacher_HTransformer_prcr.ipynb
Purpose: Similar to 2a, but for overall response
Output: A trained teacher model capable of predicting overall response based on the RECIST dataset.

##3a_train_teacher_nolongitudinal_pd.ipynb
Purpose: Trains a teacher model using non-longitudinal patient data, testing how well the model performs without longitudinal temporal sequences.
Output: A trained teacher model without reliance on sequential data for predicting progressive disease.

##3b_train_teacher_nolongitudinal_prcr.ipynb
Purpose: Similar to 3a, but for overall response using non-longitudinal patient data, testing how well the model performs without longitudinal temporal sequences.
Output: A trained teacher model without reliance on sequential data for predicting overall response.

3. Student Model Training

##4a_train_student_MIMIC_HTransformer_pd.ipynb
Purpose: Trains the student model on MIMIC-IV data using the hierarchical transformer architecture.
Output: A student model trained on proxy data (MIMIC-IV) for progressive disease.

##4b_train_student_MIMIC_HTransformer_prcr.ipynb
Purpose: Similar to 4a, but for overall response predictions using MIMIC-IV data.
Output: A student model trained on proxy data (MIMIC-IV) for overall response.

##5a_train_student_WIKItext_HTransformer_pd.ipynb
Purpose: Trains the student model on WikiText data as a proxy dataset
Output: A student model trained on WikiText data for progressive disease.

##5b_train_student_WIKItext_HTransformer_prcr.ipynb
Purpose: Similar to 5a, but for overall response predictions on WikiText data.
Output: A student model trained on WikiText data for overall response.

##6a_train_student_GPT4Synthetic_HTransformer_pd.ipynb
Purpose: Trains a student model on teacher informed GPT-4-generated synthetic data for progressive disease predictions using a hierarchical transformer.
Output: A student model trained on teacher informed GPT-4 synthetic data for progressive disease.

##6b_train_student_GPT4Synthetic_HTransformer_prcr.ipynb
Purpose: Similar to 6a, but focused on overall response predictions using GPT-4 synthetic data.
Output: A student model trained on teacher informed GPT-4 synthetic data for overall response.

##7a_train_student_only_GPT4_Synthetic_HTransformer_pd.ipynb
Purpose: Trains a student model solely on GPT-4-generated synthetic data for progressive disease predictions without teacher supervision.
Output: A standalone student model trained on GPT-4 synthetic data for progressive disease.

##7b_train_student_only_GPT4_Synthetic_HTransformer_prcr.ipynb
Purpose: Similar to 7a, but focused on overall response predictions without teacher supervision.
Output: A standalone student model trained on GPT-4 synthetic data for overall response.


##How to Use
Note: These notebooks will not run out of the box, because they require access to RECIST-labeled "teacher" training data, which are referenced but not included in the notebooks.
Data Preparation: Start with 1a_make_recist_teacher_dataset.ipynb or 1b_make_synthetic_data_gpt4.ipynb to generate the datasets required for model training.
Teacher Model Training: Use the notebooks in Section 2 to train teacher models on longitudinal and non-longitudinal datasets.
Student Model Training: Use the notebooks in Section 3 to train and evaluate student models on various datasets, including proxy (MIMIC-IV, WikiText) and synthetic (GPT-4) datasets.
