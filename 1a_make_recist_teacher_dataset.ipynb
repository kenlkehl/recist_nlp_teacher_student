{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39dd8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eac0ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting up the working directory\n",
    "\n",
    "import os\n",
    "#os.chdir('/mnt/d/Dropbox (Partners HealthCare)/impression_bert/recist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e06cc9",
   "metadata": {},
   "source": [
    "### Reading the original RECIST annotation datafile\n",
    "\n",
    "1. Using pd.read_csv to read the respective datafiles\n",
    "2. Using error_bad_lines = False to skip occasional bad lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1113755e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5470/2794614779.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  recist_labels = pd.read_csv('timc_data/timepointreport.csv', error_bad_lines = False, low_memory=False)\n",
      "Skipping line 1165: expected 14 fields, saw 16\n",
      "Skipping line 1347: expected 14 fields, saw 15\n",
      "Skipping line 1479: expected 14 fields, saw 15\n",
      "Skipping line 4840: expected 14 fields, saw 15\n",
      "Skipping line 6228: expected 14 fields, saw 15\n",
      "Skipping line 6239: expected 14 fields, saw 15\n",
      "Skipping line 6249: expected 14 fields, saw 15\n",
      "Skipping line 10127: expected 14 fields, saw 16\n",
      "Skipping line 10902: expected 14 fields, saw 15\n",
      "Skipping line 11134: expected 14 fields, saw 16\n",
      "Skipping line 11789: expected 14 fields, saw 15\n",
      "Skipping line 11898: expected 14 fields, saw 15\n",
      "Skipping line 12813: expected 14 fields, saw 15\n",
      "Skipping line 15781: expected 14 fields, saw 15\n",
      "Skipping line 15883: expected 14 fields, saw 15\n",
      "Skipping line 15932: expected 14 fields, saw 15\n",
      "Skipping line 18556: expected 14 fields, saw 15\n",
      "Skipping line 19108: expected 14 fields, saw 15\n",
      "Skipping line 19379: expected 14 fields, saw 15\n",
      "Skipping line 19735: expected 14 fields, saw 16\n",
      "Skipping line 19966: expected 14 fields, saw 15\n",
      "Skipping line 19967: expected 14 fields, saw 15\n",
      "Skipping line 19968: expected 14 fields, saw 15\n",
      "Skipping line 19969: expected 14 fields, saw 15\n",
      "Skipping line 19972: expected 14 fields, saw 15\n",
      "Skipping line 19974: expected 14 fields, saw 17\n",
      "Skipping line 19975: expected 14 fields, saw 15\n",
      "Skipping line 19986: expected 14 fields, saw 15\n",
      "Skipping line 19987: expected 14 fields, saw 15\n",
      "Skipping line 19988: expected 14 fields, saw 15\n",
      "Skipping line 19989: expected 14 fields, saw 16\n",
      "Skipping line 19990: expected 14 fields, saw 15\n",
      "Skipping line 19992: expected 14 fields, saw 15\n",
      "Skipping line 19993: expected 14 fields, saw 16\n",
      "Skipping line 20336: expected 14 fields, saw 15\n",
      "Skipping line 20506: expected 14 fields, saw 15\n",
      "Skipping line 20997: expected 14 fields, saw 16\n",
      "Skipping line 21063: expected 14 fields, saw 15\n",
      "Skipping line 22790: expected 14 fields, saw 15\n",
      "Skipping line 23443: expected 14 fields, saw 15\n",
      "Skipping line 27878: expected 14 fields, saw 15\n",
      "Skipping line 28513: expected 14 fields, saw 15\n",
      "Skipping line 28514: expected 14 fields, saw 15\n",
      "Skipping line 28556: expected 14 fields, saw 15\n",
      "Skipping line 28557: expected 14 fields, saw 15\n",
      "Skipping line 29293: expected 14 fields, saw 15\n",
      "Skipping line 29403: expected 14 fields, saw 15\n",
      "Skipping line 37025: expected 14 fields, saw 15\n",
      "Skipping line 37153: expected 14 fields, saw 15\n",
      "Skipping line 39758: expected 14 fields, saw 15\n",
      "Skipping line 39885: expected 14 fields, saw 17\n",
      "Skipping line 40355: expected 14 fields, saw 16\n",
      "Skipping line 40652: expected 14 fields, saw 19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "recist_labels = pd.read_csv('timc_data/timepointreport.csv', error_bad_lines = False, low_memory=False)\n",
    "pt_reg = pd.read_csv('../../profile_2022/oncdrs_data/REQ_KK71_105304_PT_INFO_STATUS_REGISTRATION.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b00900-aea5-4e68-bfab-84e9770dd48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51006 entries, 0 to 51005\n",
      "Data columns (total 50 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   PATIENT_ID                     51006 non-null  int64  \n",
      " 1   LAST_NM                        51006 non-null  object \n",
      " 2   FIRST_NM                       51005 non-null  object \n",
      " 3   MIDDLE_NM                      21010 non-null  object \n",
      " 4   TITLE_NM                       109 non-null    object \n",
      " 5   BIRTH_DT                       51006 non-null  object \n",
      " 6   D_BIRTH_DT                     51006 non-null  float64\n",
      " 7   AGE90_BIRTH_DT                 51006 non-null  object \n",
      " 8   HYBRID_DEATH_IND               51006 non-null  object \n",
      " 9   HYBRID_DEATH_DT                20866 non-null  object \n",
      " 10  D_HYBRID_DEATH_DT              20866 non-null  float64\n",
      " 11  AGE90_HYBRID_DEATH_DT          51006 non-null  object \n",
      " 12  HYBRID_DEATH_SOURCE            20866 non-null  object \n",
      " 13  CLIN_DEATH_DT                  15320 non-null  object \n",
      " 14  D_CLIN_DEATH_DT                15320 non-null  float64\n",
      " 15  AGE90_CLIN_DEATH_DT            51006 non-null  object \n",
      " 16  NDI_DEATH_DT                   18207 non-null  object \n",
      " 17  D_NDI_DEATH_DT                 18207 non-null  float64\n",
      " 18  AGE90_NDI_DEATH_DT             51006 non-null  object \n",
      " 19  NDI_CAUSE_OF_DEATH             18189 non-null  object \n",
      " 20  NDI_CAUSE_OF_DEATH_RECODE      18135 non-null  object \n",
      " 21  NDI_LAST_DEATH_CHECK_DATE      31458 non-null  object \n",
      " 22  DERIVED_LAST_CONTACT_DT        50395 non-null  object \n",
      " 23  D_DERIVED_LAST_CONTACT_DT      50395 non-null  float64\n",
      " 24  AGE90_DERIVED_LAST_CONTACT_DT  51006 non-null  object \n",
      " 25  DERIVED_LAST_ALIVE_DATE        50786 non-null  object \n",
      " 26  D_DERIVED_LAST_ALIVE_DATE      50786 non-null  float64\n",
      " 27  AGE90_DERIVED_LAST_ALIVE_DATE  51006 non-null  object \n",
      " 28  DERIVED_LAST_ALIVE_SRC         50786 non-null  object \n",
      " 29  GENDER_NM                      51006 non-null  object \n",
      " 30  DFCI_MRN                       51006 non-null  int64  \n",
      " 31  CHILDRENS_MRN                  2487 non-null   float64\n",
      " 32  BI_MRN                         219 non-null    object \n",
      " 33  BWH_MRN                        50462 non-null  float64\n",
      " 34  MGH_MRN                        32604 non-null  float64\n",
      " 35  EPIC_MRN                       51005 non-null  float64\n",
      " 36  DFCI_MRN_ALTERNATIVE           527 non-null    object \n",
      " 37  PRIMARY_PROGRAM_NM             49828 non-null  object \n",
      " 38  ADULT_PEDI_NM                  51006 non-null  object \n",
      " 39  ON_THERAPEUTIC_PROT_IND        4357 non-null   object \n",
      " 40  PT_DERIVED_CELL_LINES_EXIST    51006 non-null  object \n",
      " 41  PT_DERIVED_XENOGRAFTS_EXIST    51006 non-null  object \n",
      " 42  PT_LIVE_CRYO_CELLS_MAY_EXIST   51006 non-null  object \n",
      " 43  PT_ONCOPANEL_PROFILED_IND      51006 non-null  object \n",
      " 44  IDM_CREATE_DTTM                51006 non-null  object \n",
      " 45  IDM_LAST_UPD_DTTM              50956 non-null  object \n",
      " 46  SRC_INST                       51006 non-null  object \n",
      " 47  SRC_NM                         51006 non-null  object \n",
      " 48  SOURCE_EXTRACT_DTTM            51006 non-null  object \n",
      " 49  Unnamed: 49                    0 non-null      float64\n",
      "dtypes: float64(11), int64(2), object(37)\n",
      "memory usage: 19.5+ MB\n"
     ]
    }
   ],
   "source": [
    "pt_reg.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b58c61",
   "metadata": {},
   "source": [
    "### Formatting the registration datafile \n",
    "\n",
    "1. Creating a new column using the same name (MRN) as in timepoint datafile\n",
    "2. Converting the MRN numbers to numeric/integers as they are in numeric/integer format in timepoint (non-numeric will be converted into NaN)\n",
    "3. Replacing NaNs with zeros\n",
    "4. Converting MRN values into integers (originally as float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a48085de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_reg['MRN'] = pt_reg['BWH_MRN']\n",
    "pt_reg['MRN'] = pd.to_numeric(pt_reg['MRN']).fillna(0) ## need to make all MRNs numeric\n",
    "                                                                   ## with pd.to_numeric, MRNs which are not numeric will be converted to NaN                                                                    \n",
    "pt_reg['MRN'] = pt_reg['MRN'].dropna()\n",
    "pt_reg['MRN'] = pt_reg['MRN'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee754c4",
   "metadata": {},
   "source": [
    "### Merging the two datafiles (timepoint and PT_INFO_STATUS_REGISTRATION)\n",
    "\n",
    "1. The purpose of this merge is to get DFCI MRN linked to the RECIST annotations, which are indexed with a BWH MRN by default. \n",
    "2. Using pd.merge to inner merge timepoint, and registration datafiles by the common column, 'MRN'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0cbfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "recist_reg = pd.merge(recist_labels, \n",
    "                          pt_reg,\n",
    "                   on='MRN')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ba2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "recist_reg = recist_reg[['Protocol', \n",
    "                 'DFCI_MRN', \n",
    "                 'VisitDate', \n",
    "                 'OverallResponse']]\n",
    "\n",
    "recist_reg = recist_reg.rename(columns = {'VisitDate': 'date', \n",
    "                                          'DFCI_MRN': 'dfci_mrn', \n",
    "                                          'OverallResponse': 'overall_response',\n",
    "                                         'Protocol': 'protocol'})\n",
    "\n",
    "recist_reg['date'] = pd.to_datetime(pd.Series(recist_reg.date), \n",
    "                           errors = 'coerce', \n",
    "                           format = \"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def to_string(date):\n",
    "    if date:\n",
    "        string = date.strftime(\"%Y-%m-%d\")\n",
    "    else:\n",
    "        string = \"\"\n",
    "\n",
    "    return string\n",
    "\n",
    "recist_reg['date'] = recist_reg['date'].map(to_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd04f60",
   "metadata": {},
   "source": [
    "### Parsing/Reading single JSON file\n",
    "\n",
    "1. Get the file handler for a file on disk\n",
    "2. Load the content of the file by using the file handler\n",
    "3. Convert the JSON file into pd dataframe\n",
    "4. Export the dataframe as csv (not required but can be helpful)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c1626d",
   "metadata": {},
   "source": [
    "### Parsing/Reading multiple JSON files\n",
    "\n",
    "1. Create a list of JSON file paths\n",
    "2. Initiate an empty list 'dfs' to be appended later\n",
    "3. Run a for loop -\n",
    "    For each JSON file in the list of JSON files\n",
    "        open each JSON file\n",
    "        load each JSON file\n",
    "        convert each JSON file into a pd Df\n",
    "        Append the list 'dfs' with each JSON file\n",
    "4. Concatenate (combined) multiple JSON files into a dataframe\n",
    "5. Export dataframe as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ef9cfc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* parsing ../../profile_2022/text_data/RequestID-105304_Imag_File1.json\n",
      "* parsing ../../profile_2022/text_data/RequestID-105304_Imag_File2.json\n",
      "* parsing ../../profile_2022/text_data/RequestID-105304_Imag_File3.json\n",
      "* parsing ../../profile_2022/text_data/RequestID-105304_Imag_File4.json\n",
      "* combined df\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "fns = [\n",
    "    '../../profile_2022/text_data/RequestID-105304_Imag_File1.json',\n",
    "    '../../profile_2022/text_data/RequestID-105304_Imag_File2.json',\n",
    "    '../../profile_2022/text_data/RequestID-105304_Imag_File3.json',\n",
    "    '../../profile_2022/text_data/RequestID-105304_Imag_File4.json',\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "for fn in fns:\n",
    "    print('* parsing %s' % fn)\n",
    "    # get the file handler for a file on disk\n",
    "    fh = open(fn, encoding='utf8')\n",
    "    \n",
    "    # load the content of the file by using that file handler\n",
    "    j = json.load(fh)\n",
    "\n",
    "    # to save/convert a list of objects/dictionaries\n",
    "    # we will convert it first to a Pandas DataFrame first\n",
    "    dft = pd.DataFrame(j['response']['docs'])\n",
    "    \n",
    "    # combine the dft to a list\n",
    "    dfs.append(dft)\n",
    "\n",
    "# combine all df in the dfs into one df\n",
    "df = pd.concat(dfs)\n",
    "print('* combined df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd9c970",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "1. The next step is to link the text data from the parsed JSON files with the RECIST labels from the timepoint datafile\n",
    "2. This must be done at the multiple timepoints because each patient (DFCI_MRN) can have multiple scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3bc0688",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df = df.rename(columns = {'EVENT_DATE': 'date',\n",
    "                         'DFCI_MRN': 'dfci_mrn'})\n",
    "\n",
    "json_df['dfci_mrn'] = pd.to_numeric(json_df['dfci_mrn']).fillna(0)\n",
    "json_df['dfci_mrn'] = json_df['dfci_mrn'].astype(int)\n",
    "\n",
    "\n",
    "json_df['date'] = pd.to_datetime(pd.Series(json_df.date), ##Converting dates into datetime format\n",
    "                           errors = 'coerce', \n",
    "                           format = \"%Y-%m-%d\")\n",
    "\n",
    "def to_string(date): ##Defining a function to convert datetime back to string if date or else leave it empty\n",
    "    if date:\n",
    "        string = date.strftime(\"%Y-%m-%d\")\n",
    "    else:\n",
    "        string = \"\"\n",
    "\n",
    "    return string\n",
    "\n",
    "json_df['date'] = json_df['date'].map(to_string) ##Mapping function to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2918f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_df = json_df[[\"date\", ##Keeping only relevant columns from json_df\n",
    "         \"dfci_mrn\",\n",
    "        'RPT_TEXT',\n",
    "        \"NARRATIVE_TEXT\",\n",
    "        \"IMPRESSION_TEXT\",\n",
    "        \"ADDENDUM_TEXT\"]]\n",
    "\n",
    "json_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373eb4fc",
   "metadata": {},
   "source": [
    "## Merge JSON (imaging reports) to RECIST annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6eaa4da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Inner merge on date and MRN\n",
    "labeled_data = pd.merge(recist_reg, \n",
    "                    json_df,\n",
    "                    on = ['date', 'dfci_mrn'],\n",
    "                   how = 'inner')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "009f3d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Renaming column of interest\n",
    "labeled_data = labeled_data.rename(columns = {'NARRATIVE_TEXT': 'narrative_text', 'RPT_TEXT':'report_text', 'IMPRESSION_TEXT':'impression_text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd6285b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of unique DFCI MRNs are: 5163\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " SD        30867\n",
       " BL        25185\n",
       " PR        23517\n",
       " PD        15290\n",
       " CR         4459\n",
       " NN         1205\n",
       " SC         1186\n",
       " NE          707\n",
       " UN          639\n",
       " PDu         226\n",
       " NP          184\n",
       " POS          29\n",
       " CRu          17\n",
       " FS           10\n",
       " -64.9%        6\n",
       " -95%          6\n",
       " -80.1%        5\n",
       " -100%         5\n",
       " NEG           2\n",
       " 0%            1\n",
       " Name: overall_response, dtype: int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting counts of RECIST labels\n",
    "print('The total number of unique DFCI MRNs are:', len(labeled_data['dfci_mrn'].unique())), labeled_data['overall_response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d39fcdc7-32d8-4cdd-aa71-c719c892926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop obs's (trial-treatment combos) that have any non-standard annotations\n",
    "no_list = ['-64.9%', \n",
    "                                                                   '-95%', \n",
    "                                                                   '-80.1%', \n",
    "                                                                   '-100%', \n",
    "                                                                   '0%',\n",
    "                                                                  'NN',\n",
    "                                                                  'SC',\n",
    "                                                                  'NE',\n",
    "                                                                  'UN',\n",
    "                                                                  'PDu',\n",
    "                                                                  'NP',\n",
    "                                                                  'POS',\n",
    "                                                                  'CRu',\n",
    "                                                                  'FS',\n",
    "                                                                  'NEG']\n",
    "\n",
    "labeled_data['drop_this_obs'] = labeled_data.groupby(['protocol','dfci_mrn']).overall_response.transform(lambda x: (x.isin(no_list).any()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e3472de-fb0e-4d2e-a80e-04062682084e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    90149\n",
       "True     13605\n",
       "Name: drop_this_obs, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data.drop_this_obs.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00cff810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 90149\n",
      "Number of entries: 89943\n"
     ]
    }
   ],
   "source": [
    "## Removing irrelevant labels\n",
    "\n",
    "labeled_data = labeled_data[~labeled_data.drop_this_obs]\n",
    "# labeled_data = labeled_data[labeled_data['overall_response'].isin(['-64.9%', \n",
    "#                                                                    '-95%', \n",
    "#                                                                    '-80.1%', \n",
    "#                                                                    '-100%', \n",
    "#                                                                    '0%',\n",
    "#                                                                   'NN',\n",
    "#                                                                   'SC',\n",
    "#                                                                   'NE',\n",
    "#                                                                   'UN',\n",
    "#                                                                   'PDu',\n",
    "#                                                                   'NP',\n",
    "#                                                                   'POS',\n",
    "#                                                                   'CRu',\n",
    "#                                                                   'FS',\n",
    "#                                                                   'NEG']) == False]\n",
    "\n",
    "print(\"Number of entries:\", labeled_data.shape[0])\n",
    "\n",
    "\n",
    "labeled_data['overall_response'] = labeled_data['overall_response'].dropna()\n",
    "labeled_data = labeled_data[labeled_data['overall_response'].notna()]\n",
    "\n",
    "print(\"Number of entries:\", labeled_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8e2813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to predefined patient-level train/val/test splits\n",
    "splits = pd.read_csv('/mnt/d/Dropbox (Partners HealthCare)/profile_9-2022/derived_data/split_9-2022.csv')[['dfci_mrn','split']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data=pd.merge(labeled_data, splits, on='dfci_mrn', how='inner').drop(['ADDENDUM_TEXT'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e99939ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an identifier corresponding to unique combos of MRN and protocol numbers\n",
    "#patient trial combination\n",
    "#one to many relationship (patients to obs)\n",
    "#one to one (obs to pat)\n",
    "copy = labeled_data.copy()\n",
    "labeled_data['obs'] = labeled_data.groupby(['dfci_mrn','protocol']).ngroup()\n",
    "labeled_data = labeled_data.sort_values(by=['obs','date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec734eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    89943\n",
       "Name: obs, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data.obs.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa3267fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train         72529\n",
       "test           9044\n",
       "validation     8370\n",
       "Name: split, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data.split.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d810237a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BL', 'SD', 'PD', 'PR', 'CR'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Getting the unique recist labels\n",
    "labeled_data['overall_response'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2e558a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting categorical variable values (recist labels) to numerical codes\n",
    "labeled_data['overall_response_factor'] = labeled_data['overall_response'].replace([\n",
    "                        'BL', 'PR', 'CR', 'SD', 'PD'],\n",
    "                        [0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ad3b54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 89943 entries, 19994 to 57168\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   protocol                 89943 non-null  object\n",
      " 1   dfci_mrn                 89943 non-null  int64 \n",
      " 2   date                     89943 non-null  object\n",
      " 3   overall_response         89943 non-null  object\n",
      " 4   report_text              89943 non-null  object\n",
      " 5   narrative_text           89940 non-null  object\n",
      " 6   impression_text          58413 non-null  object\n",
      " 7   drop_this_obs            89943 non-null  bool  \n",
      " 8   split                    89943 non-null  object\n",
      " 9   obs                      89943 non-null  int64 \n",
      " 10  overall_response_factor  89943 non-null  int64 \n",
      "dtypes: bool(1), int64(3), object(7)\n",
      "memory usage: 7.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check variable info\n",
    "labeled_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dec9d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = labeled_data.groupby(['dfci_mrn','date','report_text']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6698bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data.to_csv('./timc_recist_labeled_dataset_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af4aae1-467a-4cbb-bab0-31ebcb6f28ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
